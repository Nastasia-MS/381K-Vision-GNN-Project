{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h8qh1n_-x5Jf",
        "outputId": "26a0823a-afd1-4878-b68d-a2836e2c6883"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch-geometric\n",
            "  Downloading torch_geometric-2.7.0-py3-none-any.whl.metadata (63 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/63.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.7/63.7 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.13.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (2025.3.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.1.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (2.0.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.2.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (2.32.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.6.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (1.22.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch-geometric) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (2025.11.12)\n",
            "Requirement already satisfied: typing-extensions>=4.2 in /usr/local/lib/python3.12/dist-packages (from aiosignal>=1.4.0->aiohttp->torch-geometric) (4.15.0)\n",
            "Downloading torch_geometric-2.7.0-py3-none-any.whl (1.3 MB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.3 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m38.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch-geometric\n",
            "Successfully installed torch-geometric-2.7.0\n"
          ]
        }
      ],
      "source": [
        "!pip install torch-geometric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "0LylL5fKw-Rr"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as T\n",
        "import torch.nn.functional as F\n",
        "from torchvision.datasets import CIFAR10\n",
        "from torch.utils.data import DataLoader\n",
        "from torch_geometric.nn import HypergraphConv, AttentionalAggregation\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "liJsPPJdmaSM",
        "outputId": "d65aadd7-6d94-4e59-f9cd-8948b5aa588b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170M/170M [00:03<00:00, 48.3MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(50000, 32, 32, 3)\n"
          ]
        }
      ],
      "source": [
        "transform = T.Compose([\n",
        "    T.ToTensor(),\n",
        "    T.Normalize(\n",
        "        mean=[0.4914, 0.4822, 0.4465],\n",
        "        std=[0.2470, 0.2435, 0.2616]\n",
        "    )\n",
        "    ])\n",
        "train_dataset = CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "test_dataset = CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "print(train_dataset.data.shape)\n",
        "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=2)\n",
        "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False, num_workers=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9hz9GKBUmaqw"
      },
      "source": [
        "# image->hypergraph"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def image_to_adaptive_hypergraph(images, k_spatial, k_feature=None):\n",
        "    \"\"\"\n",
        "    Build hypergraph with specified k values (can vary per layer).\n",
        "    If k_feature is None, only use spatial edges.\n",
        "    \"\"\"\n",
        "    batch_node_feats = []\n",
        "    batch_hyperedge_index = []\n",
        "    batch_map = []\n",
        "    node_offset = 0\n",
        "    edge_id = 0\n",
        "\n",
        "    for b, img in enumerate(images):\n",
        "        C, H, W = img.shape\n",
        "        patch_size = 8\n",
        "\n",
        "        # Extract patches\n",
        "        patches = img.unfold(1, patch_size, patch_size).unfold(2, patch_size, patch_size)\n",
        "        patches = patches.permute(1, 2, 0, 3, 4).contiguous()\n",
        "        patches = patches.view(-1, C, patch_size, patch_size)\n",
        "        node_feats = patches.view(patches.size(0), -1).to(images.device)\n",
        "        num_nodes = node_feats.size(0)\n",
        "\n",
        "        # Spatial coordinates\n",
        "        num_patches_side = W // patch_size\n",
        "        coords = torch.tensor([\n",
        "            [i // num_patches_side, i % num_patches_side]\n",
        "            for i in range(num_nodes)\n",
        "        ], device=images.device, dtype=torch.float)\n",
        "\n",
        "        dists_spatial = torch.cdist(coords, coords, p=2)\n",
        "\n",
        "        hyperedge_list = []\n",
        "\n",
        "        # Spatial hyperedges\n",
        "        for i in range(num_nodes):\n",
        "            nn_idx = torch.topk(dists_spatial[i], k=k_spatial+1, largest=False).indices\n",
        "            for node in nn_idx:\n",
        "                hyperedge_list.append([node.item() + node_offset, edge_id])\n",
        "            edge_id += 1\n",
        "\n",
        "        # Feature hyperedges (optional, for later layers)\n",
        "        if k_feature is not None and k_feature > 0:\n",
        "            dists_feat = torch.cdist(node_feats, node_feats, p=2)\n",
        "            for i in range(num_nodes):\n",
        "                nn_idx = torch.topk(dists_feat[i], k=k_feature+1, largest=False).indices\n",
        "                for node in nn_idx:\n",
        "                    hyperedge_list.append([node.item() + node_offset, edge_id])\n",
        "                edge_id += 1\n",
        "\n",
        "        batch_node_feats.append(node_feats)\n",
        "        batch_hyperedge_index.extend(hyperedge_list)\n",
        "        batch_map.append(torch.full((num_nodes,), b, dtype=torch.long, device=images.device))\n",
        "        node_offset += num_nodes\n",
        "\n",
        "    x = torch.cat(batch_node_feats, dim=0).float()\n",
        "    hyperedge_index = torch.tensor(batch_hyperedge_index, dtype=torch.long, device=images.device).T\n",
        "    batch_map = torch.cat(batch_map)\n",
        "\n",
        "    return x, hyperedge_index, batch_map\n",
        "\n",
        "\n",
        "class AdaptiveHypergraphBlock(nn.Module):\n",
        "    \"\"\"Hypergraph block that can use different k values\"\"\"\n",
        "    def __init__(self, hidden_dim, dropout=0.3, ffn_expansion=2):\n",
        "        super().__init__()\n",
        "        self.conv = HypergraphConv(hidden_dim, hidden_dim)\n",
        "        self.norm1 = nn.LayerNorm(hidden_dim, eps=1e-5)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "        self.ffn = nn.Sequential(\n",
        "            nn.Linear(hidden_dim, hidden_dim * ffn_expansion),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(hidden_dim * ffn_expansion, hidden_dim)\n",
        "        )\n",
        "        self.norm2 = nn.LayerNorm(hidden_dim, eps=1e-5)\n",
        "\n",
        "    def forward(self, x, edge_index, edge_weight):\n",
        "        # Hypergraph convolution with residual\n",
        "        x_res = x\n",
        "        x = self.conv(x, edge_index, edge_weight)\n",
        "        x = self.norm1(x)\n",
        "        x = self.dropout(F.relu(x)) + x_res\n",
        "\n",
        "        # Feedforward with residual\n",
        "        x_res = x\n",
        "        x = self.ffn(x)\n",
        "        x = self.norm2(x)\n",
        "        x = self.dropout(x) + x_res\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "class AdaptiveHyperVigClassifier(nn.Module):\n",
        "    def __init__(self, in_channels, hidden, num_classes, k_schedule=[12, 10, 8, 6, 4, 4], dropout=0.3):\n",
        "        super().__init__()\n",
        "        self.hidden = hidden\n",
        "        self.k_schedule = k_schedule  # k values for each layer\n",
        "\n",
        "        # Project patch features\n",
        "        self.input_proj = nn.Linear(in_channels, hidden)\n",
        "\n",
        "        # Multi-head edge attention (shared across layers or per-layer)\n",
        "        self.edge_attns = nn.ModuleList([\n",
        "            MultiHeadHyperedgeAttention(in_dim=hidden, hidden=64, num_heads=8)\n",
        "            for _ in k_schedule\n",
        "        ])\n",
        "\n",
        "        # Hypergraph blocks\n",
        "        self.blocks = nn.ModuleList([\n",
        "            AdaptiveHypergraphBlock(hidden, dropout=dropout)\n",
        "            for _ in k_schedule\n",
        "        ])\n",
        "\n",
        "        # Attentional pooling\n",
        "        self.pool = AttentionalAggregation(\n",
        "            gate_nn=nn.Sequential(\n",
        "                nn.Linear(hidden, hidden),\n",
        "                nn.ReLU(),\n",
        "                nn.Linear(hidden, 1)\n",
        "            )\n",
        "        )\n",
        "\n",
        "        # Classifier\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(hidden, hidden),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(hidden, num_classes)\n",
        "        )\n",
        "\n",
        "        self._init_weights()\n",
        "\n",
        "    def _init_weights(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Linear):\n",
        "                nn.init.xavier_uniform_(m.weight)\n",
        "                if m.bias is not None:\n",
        "                    nn.init.zeros_(m.bias)\n",
        "            elif isinstance(m, nn.LayerNorm):\n",
        "                nn.init.ones_(m.weight)\n",
        "                nn.init.zeros_(m.bias)\n",
        "\n",
        "    def forward(self, images, batch_map_input):\n",
        "        # Extract initial patch features\n",
        "        batch_size = images.size(0)\n",
        "        patches_per_image = 16\n",
        "\n",
        "        # Initial projection\n",
        "        x_init, _, batch_map = image_to_adaptive_hypergraph(images, k_spatial=self.k_schedule[0])\n",
        "        x = self.input_proj(x_init)\n",
        "\n",
        "        # Process through layers with evolving topology\n",
        "        for layer_idx, (k_val, block, edge_attn) in enumerate(zip(self.k_schedule, self.blocks, self.edge_attns)):\n",
        "            # Rebuild hypergraph with current k value\n",
        "            # Use feature-based edges for later layers (when features are better)\n",
        "            k_feature = k_val if layer_idx >= 2 else None  # Feature edges only in layers 3+\n",
        "\n",
        "            # Reshape x back to images to rebuild graph\n",
        "            x_reshaped = x.view(batch_size, patches_per_image, -1)\n",
        "\n",
        "            # Build new hypergraph based on current features\n",
        "            _, edge_index, _ = self.build_hypergraph_from_features(\n",
        "                x_reshaped, k_spatial=k_val, k_feature=k_feature\n",
        "            )\n",
        "\n",
        "            # Compute edge attention\n",
        "            edge_weight = edge_attn(x, edge_index)\n",
        "\n",
        "            # Apply block\n",
        "            x = block(x, edge_index, edge_weight)\n",
        "\n",
        "        # Pool and classify\n",
        "        out = self.pool(x, batch_map)\n",
        "        out = self.classifier(out)\n",
        "        return out\n",
        "\n",
        "    def build_hypergraph_from_features(self, x_batched, k_spatial, k_feature=None):\n",
        "        \"\"\"Helper to rebuild hypergraph from current node features\"\"\"\n",
        "        batch_size, num_nodes, feat_dim = x_batched.shape\n",
        "        batch_hyperedge_index = []\n",
        "        node_offset = 0\n",
        "        edge_id = 0\n",
        "\n",
        "        for b in range(batch_size):\n",
        "            x_nodes = x_batched[b]  # [num_nodes, feat_dim]\n",
        "\n",
        "            # Spatial distances (based on patch coordinates, fixed)\n",
        "            num_patches_side = 4  # 32/8 = 4\n",
        "            coords = torch.tensor([\n",
        "                [i // num_patches_side, i % num_patches_side]\n",
        "                for i in range(num_nodes)\n",
        "            ], device=x_nodes.device, dtype=torch.float)\n",
        "            dists_spatial = torch.cdist(coords, coords, p=2)\n",
        "\n",
        "            hyperedge_list = []\n",
        "\n",
        "            # Spatial hyperedges\n",
        "            for i in range(num_nodes):\n",
        "                nn_idx = torch.topk(dists_spatial[i], k=k_spatial+1, largest=False).indices\n",
        "                for node in nn_idx:\n",
        "                    hyperedge_list.append([node.item() + node_offset, edge_id])\n",
        "                edge_id += 1\n",
        "\n",
        "            # Feature hyperedges (based on learned features)\n",
        "            if k_feature is not None:\n",
        "                dists_feat = torch.cdist(x_nodes, x_nodes, p=2)\n",
        "                for i in range(num_nodes):\n",
        "                    nn_idx = torch.topk(dists_feat[i], k=k_feature+1, largest=False).indices\n",
        "                    for node in nn_idx:\n",
        "                        hyperedge_list.append([node.item() + node_offset, edge_id])\n",
        "                    edge_id += 1\n",
        "\n",
        "            batch_hyperedge_index.extend(hyperedge_list)\n",
        "            node_offset += num_nodes\n",
        "\n",
        "        edge_index = torch.tensor(batch_hyperedge_index, dtype=torch.long, device=x_batched.device).T\n",
        "        batch_map = torch.cat([torch.full((num_nodes,), b, dtype=torch.long, device=x_batched.device)\n",
        "                               for b in range(batch_size)])\n",
        "\n",
        "        return x_batched.view(-1, feat_dim), edge_index, batch_map"
      ],
      "metadata": {
        "id": "kE4_dgumMaU8"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def image_to_adaptive_hypergraph(images, k_spatial, k_feature=None):\n",
        "    \"\"\"\n",
        "    Build hypergraph with specified k values (can vary per layer).\n",
        "    If k_feature is None, only use spatial edges.\n",
        "    \"\"\"\n",
        "    batch_node_feats = []\n",
        "    batch_hyperedge_index = []\n",
        "    batch_map = []\n",
        "    node_offset = 0\n",
        "    edge_id = 0\n",
        "\n",
        "    for b, img in enumerate(images):\n",
        "        C, H, W = img.shape\n",
        "        patch_size = 8\n",
        "\n",
        "        # Extract patches\n",
        "        patches = img.unfold(1, patch_size, patch_size).unfold(2, patch_size, patch_size)\n",
        "        patches = patches.permute(1, 2, 0, 3, 4).contiguous()\n",
        "        patches = patches.view(-1, C, patch_size, patch_size)\n",
        "        node_feats = patches.view(patches.size(0), -1).to(images.device)\n",
        "        num_nodes = node_feats.size(0)\n",
        "\n",
        "        # Spatial coordinates\n",
        "        num_patches_side = W // patch_size\n",
        "        coords = torch.tensor([\n",
        "            [i // num_patches_side, i % num_patches_side]\n",
        "            for i in range(num_nodes)\n",
        "        ], device=images.device, dtype=torch.float)\n",
        "\n",
        "        dists_spatial = torch.cdist(coords, coords, p=2)\n",
        "\n",
        "        hyperedge_list = []\n",
        "\n",
        "        # Spatial hyperedges\n",
        "        for i in range(num_nodes):\n",
        "            nn_idx = torch.topk(dists_spatial[i], k=k_spatial+1, largest=False).indices\n",
        "            for node in nn_idx:\n",
        "                hyperedge_list.append([node.item() + node_offset, edge_id])\n",
        "            edge_id += 1\n",
        "\n",
        "        # Feature hyperedges (optional, for later layers)\n",
        "        if k_feature is not None and k_feature > 0:\n",
        "            dists_feat = torch.cdist(node_feats, node_feats, p=2)\n",
        "            for i in range(num_nodes):\n",
        "                nn_idx = torch.topk(dists_feat[i], k=k_feature+1, largest=False).indices\n",
        "                for node in nn_idx:\n",
        "                    hyperedge_list.append([node.item() + node_offset, edge_id])\n",
        "                edge_id += 1\n",
        "\n",
        "        batch_node_feats.append(node_feats)\n",
        "        batch_hyperedge_index.extend(hyperedge_list)\n",
        "        batch_map.append(torch.full((num_nodes,), b, dtype=torch.long, device=images.device))\n",
        "        node_offset += num_nodes\n",
        "\n",
        "    x = torch.cat(batch_node_feats, dim=0).float()\n",
        "    hyperedge_index = torch.tensor(batch_hyperedge_index, dtype=torch.long, device=images.device).T\n",
        "    batch_map = torch.cat(batch_map)\n",
        "\n",
        "    return x, hyperedge_index, batch_map\n",
        "\n",
        "\n",
        "class AdaptiveHypergraphBlock(nn.Module):\n",
        "    \"\"\"Hypergraph block that can use different k values\"\"\"\n",
        "    def __init__(self, hidden_dim, dropout=0.3, ffn_expansion=2):\n",
        "        super().__init__()\n",
        "        self.conv = HypergraphConv(hidden_dim, hidden_dim)\n",
        "        self.norm1 = nn.LayerNorm(hidden_dim, eps=1e-5)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "        self.ffn = nn.Sequential(\n",
        "            nn.Linear(hidden_dim, hidden_dim * ffn_expansion),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(hidden_dim * ffn_expansion, hidden_dim)\n",
        "        )\n",
        "        self.norm2 = nn.LayerNorm(hidden_dim, eps=1e-5)\n",
        "\n",
        "    def forward(self, x, edge_index, edge_weight):\n",
        "        # Hypergraph convolution with residual\n",
        "        x_res = x\n",
        "        x = self.conv(x, edge_index, edge_weight)\n",
        "        x = self.norm1(x)\n",
        "        x = self.dropout(F.relu(x)) + x_res\n",
        "\n",
        "        # Feedforward with residual\n",
        "        x_res = x\n",
        "        x = self.ffn(x)\n",
        "        x = self.norm2(x)\n",
        "        x = self.dropout(x) + x_res\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "class AdaptiveHyperVigClassifier(nn.Module):\n",
        "    def __init__(self, in_channels, hidden, num_classes, k_schedule=[12, 10, 8, 6, 4, 4], dropout=0.3):\n",
        "        super().__init__()\n",
        "        self.hidden = hidden\n",
        "        self.k_schedule = k_schedule  # k values for each layer\n",
        "\n",
        "        # Project patch features\n",
        "        self.input_proj = nn.Linear(in_channels, hidden)\n",
        "\n",
        "        # Multi-head edge attention (shared across layers or per-layer)\n",
        "        self.edge_attns = nn.ModuleList([\n",
        "            MultiHeadHyperedgeAttention(in_dim=hidden, hidden=64, num_heads=8)\n",
        "            for _ in k_schedule\n",
        "        ])\n",
        "\n",
        "        # Hypergraph blocks\n",
        "        self.blocks = nn.ModuleList([\n",
        "            AdaptiveHypergraphBlock(hidden, dropout=dropout)\n",
        "            for _ in k_schedule\n",
        "        ])\n",
        "\n",
        "        # Attentional pooling\n",
        "        self.pool = AttentionalAggregation(\n",
        "            gate_nn=nn.Sequential(\n",
        "                nn.Linear(hidden, hidden),\n",
        "                nn.ReLU(),\n",
        "                nn.Linear(hidden, 1)\n",
        "            )\n",
        "        )\n",
        "\n",
        "        # Classifier\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(hidden, hidden),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(hidden, num_classes)\n",
        "        )\n",
        "\n",
        "        self._init_weights()\n",
        "\n",
        "    def _init_weights(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Linear):\n",
        "                nn.init.xavier_uniform_(m.weight)\n",
        "                if m.bias is not None:\n",
        "                    nn.init.zeros_(m.bias)\n",
        "            elif isinstance(m, nn.LayerNorm):\n",
        "                nn.init.ones_(m.weight)\n",
        "                nn.init.zeros_(m.bias)\n",
        "\n",
        "    def forward(self, images, batch_map_input):\n",
        "        # Extract initial patch features\n",
        "        batch_size = images.size(0)\n",
        "        patches_per_image = 16\n",
        "\n",
        "        # Initial projection\n",
        "        x_init, _, batch_map = image_to_adaptive_hypergraph(images, k_spatial=self.k_schedule[0])\n",
        "        x = self.input_proj(x_init)\n",
        "\n",
        "        # Process through layers with evolving topology\n",
        "        for layer_idx, (k_val, block, edge_attn) in enumerate(zip(self.k_schedule, self.blocks, self.edge_attns)):\n",
        "            # Rebuild hypergraph with current k value\n",
        "            # Use feature-based edges for later layers (when features are better)\n",
        "            k_feature = k_val if layer_idx >= 2 else None  # Feature edges only in layers 3+\n",
        "\n",
        "            # Reshape x back to images to rebuild graph\n",
        "            x_reshaped = x.view(batch_size, patches_per_image, -1)\n",
        "\n",
        "            # Build new hypergraph based on current features\n",
        "            _, edge_index, _ = self.build_hypergraph_from_features(\n",
        "                x_reshaped, k_spatial=k_val, k_feature=k_feature\n",
        "            )\n",
        "\n",
        "            # Compute edge attention\n",
        "            edge_weight = edge_attn(x, edge_index)\n",
        "\n",
        "            # Apply block\n",
        "            x = block(x, edge_index, edge_weight)\n",
        "\n",
        "        # Pool and classify\n",
        "        out = self.pool(x, batch_map)\n",
        "        out = self.classifier(out)\n",
        "        return out\n",
        "\n",
        "    def build_hypergraph_from_features(self, x_batched, k_spatial, k_feature=None):\n",
        "        \"\"\"Helper to rebuild hypergraph from current node features\"\"\"\n",
        "        batch_size, num_nodes, feat_dim = x_batched.shape\n",
        "        batch_hyperedge_index = []\n",
        "        node_offset = 0\n",
        "        edge_id = 0\n",
        "\n",
        "        for b in range(batch_size):\n",
        "            x_nodes = x_batched[b]  # [num_nodes, feat_dim]\n",
        "\n",
        "            # Spatial distances (based on patch coordinates, fixed)\n",
        "            num_patches_side = 4  # 32/8 = 4\n",
        "            coords = torch.tensor([\n",
        "                [i // num_patches_side, i % num_patches_side]\n",
        "                for i in range(num_nodes)\n",
        "            ], device=x_nodes.device, dtype=torch.float)\n",
        "            dists_spatial = torch.cdist(coords, coords, p=2)\n",
        "\n",
        "            hyperedge_list = []\n",
        "\n",
        "            # Spatial hyperedges\n",
        "            for i in range(num_nodes):\n",
        "                nn_idx = torch.topk(dists_spatial[i], k=k_spatial+1, largest=False).indices\n",
        "                for node in nn_idx:\n",
        "                    hyperedge_list.append([node.item() + node_offset, edge_id])\n",
        "                edge_id += 1\n",
        "\n",
        "            # Feature hyperedges (based on learned features)\n",
        "            if k_feature is not None:\n",
        "                dists_feat = torch.cdist(x_nodes, x_nodes, p=2)\n",
        "                for i in range(num_nodes):\n",
        "                    nn_idx = torch.topk(dists_feat[i], k=k_feature+1, largest=False).indices\n",
        "                    for node in nn_idx:\n",
        "                        hyperedge_list.append([node.item() + node_offset, edge_id])\n",
        "                    edge_id += 1\n",
        "\n",
        "            batch_hyperedge_index.extend(hyperedge_list)\n",
        "            node_offset += num_nodes\n",
        "\n",
        "        edge_index = torch.tensor(batch_hyperedge_index, dtype=torch.long, device=x_batched.device).T\n",
        "        batch_map = torch.cat([torch.full((num_nodes,), b, dtype=torch.long, device=x_batched.device)\n",
        "                               for b in range(batch_size)])\n",
        "\n",
        "        return x_batched.view(-1, feat_dim), edge_index, batch_map"
      ],
      "metadata": {
        "id": "vcAQfn4JMqe3"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadHyperedgeAttention(nn.Module):\n",
        "    \"\"\"Multi-head attention for hyperedges - different heads learn different relationship types\"\"\"\n",
        "    def __init__(self, in_dim, hidden=64, num_heads=8):\n",
        "        super().__init__()\n",
        "        self.num_heads = num_heads\n",
        "        self.head_dim = hidden // num_heads\n",
        "\n",
        "        # Each head has its own MLP\n",
        "        self.attention_heads = nn.ModuleList([\n",
        "            nn.Sequential(\n",
        "                nn.Linear(in_dim, self.head_dim),\n",
        "                nn.ReLU(),\n",
        "                nn.Dropout(0.1),\n",
        "                nn.Linear(self.head_dim, 1)\n",
        "            ) for _ in range(num_heads)\n",
        "        ])\n",
        "\n",
        "        self._init_weights()\n",
        "\n",
        "    def _init_weights(self):\n",
        "        for head in self.attention_heads:\n",
        "            for m in head.modules():\n",
        "                if isinstance(m, nn.Linear):\n",
        "                    nn.init.xavier_uniform_(m.weight)\n",
        "                    if m.bias is not None:\n",
        "                        nn.init.zeros_(m.bias)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        \"\"\"\n",
        "        x: [num_nodes, feature_dim]\n",
        "        edge_index: [2, num_connections] - format: [node_ids, hyperedge_ids]\n",
        "        Returns: edge weights [num_unique_hyperedges]\n",
        "        \"\"\"\n",
        "        node_idx, hyperedge_idx = edge_index\n",
        "        num_hyperedges = hyperedge_idx.max().item() + 1\n",
        "\n",
        "        # Aggregate node features for each hyperedge (mean pooling)\n",
        "        hyperedge_feats = torch.zeros(num_hyperedges, x.size(1), device=x.device, dtype=x.dtype)\n",
        "        hyperedge_feats.index_add_(0, hyperedge_idx, x[node_idx])\n",
        "\n",
        "        # Count nodes per hyperedge for proper averaging\n",
        "        counts = torch.zeros(num_hyperedges, device=x.device, dtype=x.dtype)\n",
        "        counts.index_add_(0, hyperedge_idx, torch.ones_like(node_idx, dtype=x.dtype))\n",
        "        hyperedge_feats = hyperedge_feats / counts.unsqueeze(1).clamp(min=1)\n",
        "\n",
        "        # Compute attention with each head\n",
        "        head_weights = []\n",
        "        for head in self.attention_heads:\n",
        "            alpha = head(hyperedge_feats).squeeze(-1)\n",
        "            alpha = torch.clamp(alpha, min=-5, max=5)\n",
        "            head_weights.append(torch.sigmoid(alpha))\n",
        "\n",
        "        # Average across heads\n",
        "        avg_weight = torch.stack(head_weights).mean(0)\n",
        "\n",
        "        # Scale to [0.1, 1.0] range\n",
        "        return avg_weight * 0.9 + 0.1"
      ],
      "metadata": {
        "id": "jcRZrfqpNEIA"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xhd8DuGXlRN3"
      },
      "outputs": [],
      "source": [
        "def image_to_true_hypergraph(images, k_spatial=4, k_feature=4):\n",
        "    batch_node_feats = []\n",
        "    batch_hyperedge_index = []\n",
        "    batch_map = []\n",
        "    node_offset = 0\n",
        "    edge_id = 0\n",
        "\n",
        "    for b, img in enumerate(images):\n",
        "        C, H, W = img.shape\n",
        "        patch_size = 8\n",
        "\n",
        "        # Extract patches\n",
        "        patches = img.unfold(1, patch_size, patch_size).unfold(2, patch_size, patch_size)\n",
        "        patches = patches.permute(1, 2, 0, 3, 4).contiguous()\n",
        "        patches = patches.view(-1, C, patch_size, patch_size)\n",
        "        node_feats = patches.view(patches.size(0), -1).to(images.device)\n",
        "        num_nodes = node_feats.size(0)\n",
        "\n",
        "        # Spatial coordinates for spatial hyperedges\n",
        "        coords = torch.tensor([\n",
        "            [i // (W // patch_size), i % (W // patch_size)]\n",
        "            for i in range(num_nodes)\n",
        "        ], device=images.device, dtype=torch.float)\n",
        "\n",
        "        dists_spatial = torch.cdist(coords, coords, p=2)\n",
        "\n",
        "        # Feature distances for feature-based hyperedges\n",
        "        dists_feat = torch.cdist(node_feats, node_feats, p=2)\n",
        "\n",
        "        hyperedge_list = []\n",
        "\n",
        "        # Spatial hyperedges: for each node, create a hyperedge with its k nearest spatial neighbors\n",
        "        for i in range(num_nodes):\n",
        "            nn_idx = torch.topk(dists_spatial[i], k=k_spatial+1, largest=False).indices\n",
        "            # Create hyperedge: all these nodes belong to one hyperedge\n",
        "            for node in nn_idx:\n",
        "                hyperedge_list.append([node.item() + node_offset, edge_id])\n",
        "            edge_id += 1\n",
        "\n",
        "        # Feature hyperedges: for each node, create a hyperedge with its k nearest feature neighbors\n",
        "        for i in range(num_nodes):\n",
        "            nn_idx = torch.topk(dists_feat[i], k=k_feature+1, largest=False).indices\n",
        "            for node in nn_idx:\n",
        "                hyperedge_list.append([node.item() + node_offset, edge_id])\n",
        "            edge_id += 1\n",
        "\n",
        "        batch_node_feats.append(node_feats)\n",
        "        batch_hyperedge_index.extend(hyperedge_list)\n",
        "        batch_map.append(torch.full((num_nodes,), b, dtype=torch.long, device=images.device))\n",
        "        node_offset += num_nodes\n",
        "\n",
        "    x = torch.cat(batch_node_feats, dim=0).float()\n",
        "    # Convert to PyG hypergraph format: [2, num_edges] where row 0 is nodes, row 1 is hyperedge IDs\n",
        "    hyperedge_index = torch.tensor(batch_hyperedge_index, dtype=torch.long, device=images.device).T\n",
        "    batch_map = torch.cat(batch_map)\n",
        "\n",
        "    return x, hyperedge_index, batch_map"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nn_erF0rz2v2"
      },
      "outputs": [],
      "source": [
        "class HyperedgeAttention(nn.Module):\n",
        "    \"\"\"Learnable hyperedge attention that's part of the model's forward pass\"\"\"\n",
        "    def __init__(self, in_dim, hidden=64):\n",
        "        super().__init__()\n",
        "        self.mlp = nn.Sequential(\n",
        "            nn.Linear(in_dim, hidden),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden, 1)\n",
        "        )\n",
        "        self._init_weights()\n",
        "\n",
        "    def _init_weights(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Linear):\n",
        "                nn.init.xavier_uniform_(m.weight)\n",
        "                if m.bias is not None:\n",
        "                    nn.init.zeros_(m.bias)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        \"\"\"\n",
        "        Compute attention weights for each hyperedge based on aggregated node features.\n",
        "\n",
        "        x: [num_nodes, feature_dim]\n",
        "        edge_index: [2, num_connections] - format: [node_ids, hyperedge_ids]\n",
        "        Returns: edge weights [num_unique_hyperedges]\n",
        "        \"\"\"\n",
        "        node_idx, hyperedge_idx = edge_index\n",
        "        num_hyperedges = hyperedge_idx.max().item() + 1\n",
        "\n",
        "        # Aggregate node features for each hyperedge (mean pooling)\n",
        "        hyperedge_feats = torch.zeros(num_hyperedges, x.size(1), device=x.device, dtype=x.dtype)\n",
        "\n",
        "        # Use scatter_mean to aggregate features\n",
        "        hyperedge_feats.index_add_(0, hyperedge_idx, x[node_idx])\n",
        "\n",
        "        # Count nodes per hyperedge for proper averaging\n",
        "        counts = torch.zeros(num_hyperedges, device=x.device, dtype=x.dtype)\n",
        "        counts.index_add_(0, hyperedge_idx, torch.ones_like(node_idx, dtype=x.dtype))\n",
        "        hyperedge_feats = hyperedge_feats / counts.unsqueeze(1).clamp(min=1)\n",
        "\n",
        "        # Compute attention scores\n",
        "        alpha = self.mlp(hyperedge_feats).squeeze(-1)\n",
        "        alpha = torch.clamp(alpha, min=-5, max=5)\n",
        "\n",
        "        # prevent zero weights\n",
        "        return torch.sigmoid(alpha) * 0.9 + 0.1\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class HypergraphBlock(nn.Module):\n",
        "    def __init__(self, hidden_dim, dropout=0.3, ffn_expansion=2):\n",
        "        super().__init__()\n",
        "        self.conv = HypergraphConv(hidden_dim, hidden_dim)\n",
        "        self.norm1 = nn.LayerNorm(hidden_dim, eps=1e-5)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "        self.ffn = nn.Sequential(\n",
        "            nn.Linear(hidden_dim, hidden_dim * ffn_expansion),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(hidden_dim * ffn_expansion, hidden_dim)\n",
        "        )\n",
        "        self.norm2 = nn.LayerNorm(hidden_dim, eps=1e-5)\n",
        "\n",
        "    def forward(self, x, edge_index, edge_weight):\n",
        "        # Hypergraph conv w/ residual\n",
        "        x_res = x\n",
        "        x = self.conv(x, edge_index, edge_weight)\n",
        "        x = self.norm1(x)\n",
        "        x = self.dropout(F.relu(x)) + x_res\n",
        "\n",
        "        # Feedforward network w/ residual\n",
        "        x_res = x\n",
        "        x = self.ffn(x)\n",
        "        x = self.norm2(x)\n",
        "        x = self.dropout(x) + x_res\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "HnzWEkH2HBBA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class HyperedgeToHyperedgeLayer(nn.Module):\n",
        "    \"\"\"Allow hyperedges to exchange information with each other\"\"\"\n",
        "    def __init__(self, hidden_dim):\n",
        "        super().__init__()\n",
        "        # MLP for hyperedge message passing\n",
        "        self.hyperedge_mlp = nn.Sequential(\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim, hidden_dim)\n",
        "        )\n",
        "\n",
        "    def forward(self, x, edge_index, edge_weights):\n",
        "        \"\"\"\n",
        "        x: node features [num_nodes, hidden]\n",
        "        edge_index: [2, num_connections]\n",
        "        edge_weights: [num_hyperedges]\n",
        "\n",
        "        Returns: updated edge_weights\n",
        "        \"\"\"\n",
        "        node_idx, hyperedge_idx = edge_index\n",
        "        num_hyperedges = hyperedge_idx.max().item() + 1\n",
        "\n",
        "        # Aggregate node features per hyperedge\n",
        "        hyperedge_feats = torch.zeros(num_hyperedges, x.size(1), device=x.device, dtype=x.dtype)\n",
        "        hyperedge_feats.index_add_(0, hyperedge_idx, x[node_idx])\n",
        "        counts = torch.zeros(num_hyperedges, device=x.device, dtype=x.dtype)\n",
        "        counts.index_add_(0, hyperedge_idx, torch.ones_like(node_idx, dtype=x.dtype))\n",
        "        hyperedge_feats = hyperedge_feats / counts.unsqueeze(1).clamp(min=1)\n",
        "\n",
        "        # Build dual graph: hyperedges that share nodes are connected\n",
        "        # Two hyperedges are neighbors if they share at least one node\n",
        "        dual_edges = self.build_dual_graph(edge_index, num_hyperedges)\n",
        "\n",
        "        # Message passing between hyperedges\n",
        "        hyperedge_feats_updated = hyperedge_feats.clone()\n",
        "        for src, dst in dual_edges.T:\n",
        "            # Hyperedge src sends message to hyperedge dst\n",
        "            message = self.hyperedge_mlp(hyperedge_feats[src])\n",
        "            hyperedge_feats_updated[dst] += 0.1 * message  # Small update\n",
        "\n",
        "        # Update edge weights based on new hyperedge features\n",
        "        edge_weights_updated = hyperedge_feats_updated.norm(dim=1)\n",
        "        edge_weights_updated = edge_weights_updated / edge_weights_updated.max()  # Normalize\n",
        "        edge_weights_updated = edge_weights_updated * 0.9 + 0.1  # Scale to [0.1, 1.0]\n",
        "\n",
        "        return edge_weights_updated\n",
        "\n",
        "    def build_dual_graph(self, edge_index, num_hyperedges):\n",
        "        \"\"\"Build graph where hyperedges that share nodes are connected\"\"\"\n",
        "        node_idx, hyperedge_idx = edge_index\n",
        "\n",
        "        # For each node, find which hyperedges it belongs to\n",
        "        node_to_hyperedges = {}\n",
        "        for node, hedge in zip(node_idx.tolist(), hyperedge_idx.tolist()):\n",
        "            if node not in node_to_hyperedges:\n",
        "                node_to_hyperedges[node] = []\n",
        "            node_to_hyperedges[node].append(hedge)\n",
        "\n",
        "        # Build edges between hyperedges that share nodes\n",
        "        dual_edges = set()\n",
        "        for node, hedges in node_to_hyperedges.items():\n",
        "            # Connect all pairs of hyperedges that share this node\n",
        "            for i in range(len(hedges)):\n",
        "                for j in range(i+1, len(hedges)):\n",
        "                    dual_edges.add((hedges[i], hedges[j]))\n",
        "                    dual_edges.add((hedges[j], hedges[i]))  # Bidirectional\n",
        "\n",
        "        if len(dual_edges) == 0:\n",
        "            return torch.empty((2, 0), dtype=torch.long, device=edge_index.device)\n",
        "\n",
        "        return torch.tensor(list(dual_edges), dtype=torch.long, device=edge_index.device).T\n",
        "\n",
        "\n",
        "class HypergraphBlockWithH2H(nn.Module):\n",
        "    \"\"\"Hypergraph block with hyperedge-to-hyperedge communication\"\"\"\n",
        "    def __init__(self, hidden_dim, dropout=0.3, ffn_expansion=2):\n",
        "        super().__init__()\n",
        "        self.conv = HypergraphConv(hidden_dim, hidden_dim)\n",
        "        self.norm1 = nn.LayerNorm(hidden_dim, eps=1e-5)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "        # Hyperedge-to-hyperedge layer\n",
        "        self.h2h = HyperedgeToHyperedgeLayer(hidden_dim)\n",
        "\n",
        "        self.ffn = nn.Sequential(\n",
        "            nn.Linear(hidden_dim, hidden_dim * ffn_expansion),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(hidden_dim * ffn_expansion, hidden_dim)\n",
        "        )\n",
        "        self.norm2 = nn.LayerNorm(hidden_dim, eps=1e-5)\n",
        "\n",
        "    def forward(self, x, edge_index, edge_weight):\n",
        "        # Update edge weights via hyperedge communication\n",
        "        edge_weight_updated = self.h2h(x, edge_index, edge_weight)\n",
        "\n",
        "        # Hypergraph convolution with updated weights\n",
        "        x_res = x\n",
        "        x = self.conv(x, edge_index, edge_weight_updated)\n",
        "        x = self.norm1(x)\n",
        "        x = self.dropout(F.relu(x)) + x_res\n",
        "\n",
        "        # Feedforward\n",
        "        x_res = x\n",
        "        x = self.ffn(x)\n",
        "        x = self.norm2(x)\n",
        "        x = self.dropout(x) + x_res\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "mGg7l9yQNOPb"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LearnablePatchExtractor(nn.Module):\n",
        "    \"\"\"Learn where to extract patches instead of fixed grid\"\"\"\n",
        "    def __init__(self, num_patches=16, patch_size=8, img_size=32):\n",
        "        super().__init__()\n",
        "        self.num_patches = num_patches\n",
        "        self.patch_size = patch_size\n",
        "        self.img_size = img_size\n",
        "\n",
        "        # Network to predict patch locations\n",
        "        self.localization_net = nn.Sequential(\n",
        "            # Input: flattened image\n",
        "            nn.Linear(3 * img_size * img_size, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.1),\n",
        "            nn.Linear(512, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.1),\n",
        "            nn.Linear(256, num_patches * 2)  # (x, y) for each patch\n",
        "        )\n",
        "\n",
        "        # Initialize to uniform grid\n",
        "        self._init_grid()\n",
        "\n",
        "    def _init_grid(self):\n",
        "        \"\"\"Initialize to predict uniform grid (like current fixed patches)\"\"\"\n",
        "        grid_coords = []\n",
        "        patches_per_side = int(np.sqrt(self.num_patches))\n",
        "        spacing = self.img_size / patches_per_side\n",
        "\n",
        "        for i in range(patches_per_side):\n",
        "            for j in range(patches_per_side):\n",
        "                x = (i + 0.5) * spacing\n",
        "                y = (j + 0.5) * spacing\n",
        "                grid_coords.extend([x / self.img_size, y / self.img_size])  # Normalize to [0,1]\n",
        "\n",
        "        # Set final layer bias to these coordinates\n",
        "        with torch.no_grad():\n",
        "            self.localization_net[-1].bias.copy_(torch.tensor(grid_coords))\n",
        "\n",
        "    def forward(self, images):\n",
        "        \"\"\"\n",
        "        images: [batch, 3, 32, 32]\n",
        "        Returns: patches [batch, num_patches, 3, patch_size, patch_size]\n",
        "                 coordinates [batch, num_patches, 2] for visualization\n",
        "        \"\"\"\n",
        "        batch_size = images.size(0)\n",
        "\n",
        "        # Predict patch locations\n",
        "        coords = self.localization_net(images.view(batch_size, -1))\n",
        "        coords = coords.view(batch_size, self.num_patches, 2)\n",
        "        coords = torch.sigmoid(coords)  # Scale to [0, 1]\n",
        "\n",
        "        # Extract patches at predicted locations using grid_sample\n",
        "        patches = []\n",
        "        for b in range(batch_size):\n",
        "            batch_patches = []\n",
        "            for p in range(self.num_patches):\n",
        "                x, y = coords[b, p]\n",
        "\n",
        "                # Convert to pixel coordinates\n",
        "                x_pix = x * self.img_size\n",
        "                y_pix = y * self.img_size\n",
        "\n",
        "                # Create sampling grid for this patch\n",
        "                grid = self.create_patch_grid(x_pix, y_pix, self.patch_size)\n",
        "                grid = grid.unsqueeze(0).to(images.device)\n",
        "\n",
        "                # Extract patch\n",
        "                patch = F.grid_sample(\n",
        "                    images[b:b+1],\n",
        "                    grid,\n",
        "                    mode='bilinear',\n",
        "                    padding_mode='border',\n",
        "                    align_corners=True\n",
        "                )\n",
        "                batch_patches.append(patch)\n",
        "\n",
        "            patches.append(torch.cat(batch_patches, dim=0))\n",
        "\n",
        "        patches = torch.stack(patches)  # [batch, num_patches, 3, patch_size, patch_size]\n",
        "\n",
        "        return patches, coords\n",
        "\n",
        "    def create_patch_grid(self, center_x, center_y, size):\n",
        "        \"\"\"Create sampling grid for extracting a patch\"\"\"\n",
        "        # Grid in normalized coordinates [-1, 1]\n",
        "        half_size = size / 2\n",
        "\n",
        "        x_min = (center_x - half_size) / self.img_size * 2 - 1\n",
        "        x_max = (center_x + half_size) / self.img_size * 2 - 1\n",
        "        y_min = (center_y - half_size) / self.img_size * 2 - 1\n",
        "        y_max = (center_y + half_size) / self.img_size * 2 - 1\n",
        "\n",
        "        x = torch.linspace(x_min, x_max, size)\n",
        "        y = torch.linspace(y_min, y_max, size)\n",
        "\n",
        "        grid_y, grid_x = torch.meshgrid(y, x, indexing='ij')\n",
        "        grid = torch.stack([grid_x, grid_y], dim=-1)\n",
        "\n",
        "        return grid\n",
        "\n",
        "\n",
        "class LearnablePatchHyperViG(nn.Module):\n",
        "    def __init__(self, hidden, num_classes, num_patches=16, dropout=0.3):\n",
        "        super().__init__()\n",
        "\n",
        "        # Learnable patch extractor\n",
        "        self.patch_extractor = LearnablePatchExtractor(num_patches=num_patches)\n",
        "\n",
        "        self.input_proj = nn.Linear(3 * 8 * 8, hidden)\n",
        "        self.edge_attn = MultiHeadHyperedgeAttention(in_dim=hidden, hidden=64, num_heads=8)\n",
        "\n",
        "        self.blocks = nn.ModuleList([\n",
        "            HypergraphBlockWithH2H(hidden, dropout=dropout)\n",
        "            for _ in range(6)\n",
        "        ])\n",
        "\n",
        "        self.pool = AttentionalAggregation(\n",
        "            gate_nn=nn.Sequential(\n",
        "                nn.Linear(hidden, hidden),\n",
        "                nn.ReLU(),\n",
        "                nn.Linear(hidden, 1)\n",
        "            )\n",
        "        )\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(hidden, hidden),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(hidden, num_classes)\n",
        "        )\n",
        "\n",
        "        self._init_weights()\n",
        "\n",
        "    def _init_weights(self):\n",
        "        \"\"\"Add this method!\"\"\"\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Linear):\n",
        "                nn.init.xavier_uniform_(m.weight)\n",
        "                if m.bias is not None:\n",
        "                    nn.init.zeros_(m.bias)\n",
        "            elif isinstance(m, nn.LayerNorm):\n",
        "                nn.init.ones_(m.weight)\n",
        "                nn.init.zeros_(m.bias)\n",
        "\n",
        "    def forward(self, images):\n",
        "        # Extract patches at learned locations\n",
        "        patches, coords = self.patch_extractor(images)  # [batch, num_patches, 3, 8, 8]\n",
        "\n",
        "        # Flatten patches\n",
        "        batch_size, num_patches = patches.shape[:2]\n",
        "        patches_flat = patches.view(batch_size * num_patches, -1)\n",
        "\n",
        "        # Build hypergraph based on learned patch locations\n",
        "        # Use coords to compute distances\n",
        "        x, edge_index, batch_map = self.build_hypergraph_from_coords(\n",
        "            patches_flat, coords, batch_size\n",
        "        )\n",
        "\n",
        "        # Project features\n",
        "        x = self.input_proj(x)\n",
        "\n",
        "        # Compute edge attention\n",
        "        edge_weight = self.edge_attn(x, edge_index)\n",
        "\n",
        "        # Process through blocks\n",
        "        for block in self.blocks:\n",
        "            x = block(x, edge_index, edge_weight)\n",
        "\n",
        "        # Pool and classify\n",
        "        out = self.pool(x, batch_map)\n",
        "        out = self.classifier(out)\n",
        "\n",
        "        return out, coords  # Return coords for visualization\n",
        "\n",
        "    def build_hypergraph_from_coords(self, patches_flat, coords, batch_size):\n",
        "        \"\"\"Build hypergraph based on learned patch coordinates\"\"\"\n",
        "        num_patches = coords.size(1)\n",
        "        batch_hyperedge_index = []\n",
        "        node_offset = 0\n",
        "        edge_id = 0\n",
        "\n",
        "        for b in range(batch_size):\n",
        "            # Compute distances between patch centers\n",
        "            patch_coords = coords[b]  # [num_patches, 2]\n",
        "            dists = torch.cdist(patch_coords, patch_coords, p=2)\n",
        "\n",
        "            hyperedge_list = []\n",
        "            k = 8  # Number of neighbors\n",
        "\n",
        "            for i in range(num_patches):\n",
        "                nn_idx = torch.topk(dists[i], k=k+1, largest=False).indices\n",
        "                for node in nn_idx:\n",
        "                    hyperedge_list.append([node.item() + node_offset, edge_id])\n",
        "                edge_id += 1\n",
        "\n",
        "            batch_hyperedge_index.extend(hyperedge_list)\n",
        "            node_offset += num_patches\n",
        "\n",
        "        edge_index = torch.tensor(batch_hyperedge_index, dtype=torch.long, device=patches_flat.device).T\n",
        "        batch_map = torch.cat([\n",
        "            torch.full((num_patches,), b, dtype=torch.long, device=patches_flat.device)\n",
        "            for b in range(batch_size)\n",
        "        ])\n",
        "\n",
        "        return patches_flat, edge_index, batch_map"
      ],
      "metadata": {
        "id": "YipVV_f8NSpN"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MXckrB9QxtpA"
      },
      "outputs": [],
      "source": [
        "class HyperVigClassifier(nn.Module):\n",
        "    def __init__(self, in_channels, hidden, num_classes, num_blocks=3, dropout=0.3):\n",
        "        super().__init__()\n",
        "        self.hidden = hidden\n",
        "        self.input_proj = nn.Linear(in_channels, hidden)\n",
        "        #self.edge_attn = HyperedgeAttention(in_dim=hidden, hidden=64)\n",
        "        #try new\n",
        "        self.edge_attn = MultiHeadHyperedgeAttention(in_dim=hidden, hidden=64, num_heads=8)\n",
        "\n",
        "        # Multiple hypergraph blocks (each with its own FFN)\n",
        "        self.blocks = nn.ModuleList([\n",
        "            HypergraphBlock(hidden, dropout=dropout)\n",
        "            for _ in range(num_blocks)\n",
        "        ])\n",
        "\n",
        "        self.pool = AttentionalAggregation(\n",
        "            gate_nn=nn.Sequential(\n",
        "                nn.Linear(hidden, hidden),\n",
        "                nn.ReLU(),\n",
        "                nn.Linear(hidden, 1)\n",
        "            )\n",
        "        )\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(hidden, hidden),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(hidden, num_classes)\n",
        "        )\n",
        "\n",
        "        self._init_weights()\n",
        "\n",
        "    def _init_weights(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Linear):\n",
        "                nn.init.xavier_uniform_(m.weight)\n",
        "                if m.bias is not None:\n",
        "                    nn.init.zeros_(m.bias)\n",
        "            elif isinstance(m, nn.LayerNorm):\n",
        "                nn.init.ones_(m.weight)\n",
        "                nn.init.zeros_(m.bias)\n",
        "\n",
        "    def forward(self, x, edge_index, batch_map):\n",
        "        x = self.input_proj(x)  # [num_nodes, hidden]\n",
        "\n",
        "        # Compute hyperedge weights in forward pass so gradients flow\n",
        "        num_hyperedges = edge_index[1].max().item() + 1\n",
        "        hyperedge_weight = self.edge_attn(x, edge_index)\n",
        "\n",
        "        # Apply hypergraph blocks (each with its own FFN)\n",
        "        for block in self.blocks:\n",
        "            x = block(x, edge_index, hyperedge_weight)\n",
        "\n",
        "        out = self.pool(x, batch_map)  # [batch_size, hidden]\n",
        "\n",
        "        out = self.classifier(out)  # [batch_size, num_classes]\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_epoch(model, loader, optimizer, criterion, device):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for images, labels in loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        node_feats, edge_index, batch_map = image_to_true_hypergraph(images)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(node_feats, edge_index, batch_map)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "\n",
        "        # Gradient clipping for stability\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item() * images.size(0)\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    return total_loss / total, correct / total\n",
        "\n",
        "def validate(model, loader, criterion, device):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            node_feats, edge_index, batch_map = image_to_true_hypergraph(images)\n",
        "\n",
        "            outputs = model(node_feats, edge_index, batch_map)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            total_loss += loss.item() * images.size(0)\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    return total_loss / total, correct / total"
      ],
      "metadata": {
        "id": "nBRwFbmuHf8z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "model = LearnablePatchHyperViG(\n",
        "    hidden=384,\n",
        "    num_classes=10,\n",
        "    num_patches=16,\n",
        "    dropout=0.2\n",
        ").to(device)\n",
        "\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=0.002, weight_decay=0.005)\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=120, eta_min=1e-5)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(120):\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        outputs, coords = model(images)  # coords for visualization\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        coord_diversity_loss = -coords.std()\n",
        "        loss = loss + 0.001 * coord_diversity_loss\n",
        "\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GR-nouBGNW05",
        "outputId": "c791b44a-3caf-4659-e5f9-adb585307abe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}