# -*- coding: utf-8 -*-
"""Dynamic Hypergraph Edge Attention.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1HvCUphCF-PAsJrY7090_HjtdZEPybaKT
"""

# pip install torch-geometric  # Commented out - for Colab use only, not needed in regular Python scripts

import numpy as np
import torch
import torch.nn as nn
import torchvision.transforms as T
import torch.nn.functional as F
from torchvision.datasets import CIFAR10
from torch.utils.data import DataLoader
from torch_geometric.nn import HypergraphConv, AttentionalAggregation
import matplotlib
matplotlib.use('Agg')  # Use non-interactive backend for SSH
import matplotlib.pyplot as plt

transform = T.Compose([
    T.ToTensor(),
    T.Normalize(
        mean=[0.4914, 0.4822, 0.4465],
        std=[0.2470, 0.2435, 0.2616]
    )
    ])
train_dataset = CIFAR10(root='./data', train=True, download=True, transform=transform)
test_dataset = CIFAR10(root='./data', train=False, download=True, transform=transform)

print(train_dataset.data.shape)
train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)
test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)

"""# image->hypergraph"""

def image_to_true_hypergraph(images, k_spatial=4, k_feature=4):
    batch_node_feats = []
    batch_hyperedge_index = []
    batch_map = []
    node_offset = 0
    edge_id = 0

    for b, img in enumerate(images):
        C, H, W = img.shape
        patch_size = 8

        # Extract patches
        patches = img.unfold(1, patch_size, patch_size).unfold(2, patch_size, patch_size)
        patches = patches.permute(1, 2, 0, 3, 4).contiguous()
        patches = patches.view(-1, C, patch_size, patch_size)
        node_feats = patches.view(patches.size(0), -1).to(images.device)
        num_nodes = node_feats.size(0)

        # Spatial coordinates for spatial hyperedges
        coords = torch.tensor([
            [i // (W // patch_size), i % (W // patch_size)]
            for i in range(num_nodes)
        ], device=images.device, dtype=torch.float)

        dists_spatial = torch.cdist(coords, coords, p=2)

        # Feature distances for feature-based hyperedges
        dists_feat = torch.cdist(node_feats, node_feats, p=2)

        # Create TRUE hyperedges (each hyperedge connects k+1 nodes)
        hyperedge_list = []

        # Spatial hyperedges: for each node, create a hyperedge with its k nearest spatial neighbors
        for i in range(num_nodes):
            nn_idx = torch.topk(dists_spatial[i], k=k_spatial+1, largest=False).indices
            # Create hyperedge: all these nodes belong to one hyperedge
            for node in nn_idx:
                hyperedge_list.append([node.item() + node_offset, edge_id])
            edge_id += 1

        # Feature hyperedges: for each node, create a hyperedge with its k nearest feature neighbors
        for i in range(num_nodes):
            nn_idx = torch.topk(dists_feat[i], k=k_feature+1, largest=False).indices
            for node in nn_idx:
                hyperedge_list.append([node.item() + node_offset, edge_id])
            edge_id += 1

        batch_node_feats.append(node_feats)
        batch_hyperedge_index.extend(hyperedge_list)
        batch_map.append(torch.full((num_nodes,), b, dtype=torch.long, device=images.device))
        node_offset += num_nodes

    x = torch.cat(batch_node_feats, dim=0).float()
    # Convert to PyG hypergraph format: [2, num_edges] where row 0 is nodes, row 1 is hyperedge IDs
    hyperedge_index = torch.tensor(batch_hyperedge_index, dtype=torch.long, device=images.device).T
    batch_map = torch.cat(batch_map)

    return x, hyperedge_index, batch_map

class HyperedgeAttention(nn.Module):
    """Learnable hyperedge attention that's part of the model's forward pass"""
    def __init__(self, in_dim, hidden=64):
        super().__init__()
        self.mlp = nn.Sequential(
            nn.Linear(in_dim, hidden),
            nn.ReLU(),
            nn.Linear(hidden, 1)
        )
        self._init_weights()

    def _init_weights(self):
        for m in self.modules():
            if isinstance(m, nn.Linear):
                nn.init.xavier_uniform_(m.weight)
                if m.bias is not None:
                    nn.init.zeros_(m.bias)

    def forward(self, x, edge_index):
        """
        Compute attention weights for each hyperedge based on aggregated node features.

        x: [num_nodes, feature_dim]
        edge_index: [2, num_connections] - format: [node_ids, hyperedge_ids]
        Returns: edge weights [num_unique_hyperedges]
        """
        node_idx, hyperedge_idx = edge_index
        num_hyperedges = hyperedge_idx.max().item() + 1

        # Aggregate node features for each hyperedge (mean pooling)
        hyperedge_feats = torch.zeros(num_hyperedges, x.size(1), device=x.device, dtype=x.dtype)

        # Use scatter_mean to aggregate features
        hyperedge_feats.index_add_(0, hyperedge_idx, x[node_idx])

        # Count nodes per hyperedge for proper averaging
        counts = torch.zeros(num_hyperedges, device=x.device, dtype=x.dtype)
        counts.index_add_(0, hyperedge_idx, torch.ones_like(node_idx, dtype=x.dtype))
        hyperedge_feats = hyperedge_feats / counts.unsqueeze(1).clamp(min=1)

        # Compute attention scores
        alpha = self.mlp(hyperedge_feats).squeeze(-1)
        alpha = torch.clamp(alpha, min=-5, max=5)

        # prevent zero weights
        return torch.sigmoid(alpha) * 0.9 + 0.1

class HypergraphBlock(nn.Module):
    def __init__(self, hidden_dim, dropout=0.3, ffn_expansion=2):
        super().__init__()
        self.conv = HypergraphConv(hidden_dim, hidden_dim)
        self.norm1 = nn.LayerNorm(hidden_dim, eps=1e-5)
        self.dropout = nn.Dropout(dropout)

        self.ffn = nn.Sequential(
            nn.Linear(hidden_dim, hidden_dim * ffn_expansion),
            nn.ReLU(),
            nn.Dropout(dropout),
            nn.Linear(hidden_dim * ffn_expansion, hidden_dim)
        )
        self.norm2 = nn.LayerNorm(hidden_dim, eps=1e-5)

    def forward(self, x, edge_index, edge_weight):
        # Hypergraph conv w/ residual
        x_res = x
        x = self.conv(x, edge_index, edge_weight)
        x = self.norm1(x)
        x = self.dropout(F.relu(x)) + x_res

        # Feedforward network w/ residual
        x_res = x
        x = self.ffn(x)
        x = self.norm2(x)
        x = self.dropout(x) + x_res

        return x

class HyperVigClassifier(nn.Module):
    def __init__(self, in_channels, hidden, num_classes, num_blocks=3, dropout=0.3):
        super().__init__()
        self.hidden = hidden
        self.input_proj = nn.Linear(in_channels, hidden)
        self.edge_attn = HyperedgeAttention(in_dim=hidden, hidden=64)

        # Multiple hypergraph blocks (each with its own FFN)
        self.blocks = nn.ModuleList([
            HypergraphBlock(hidden, dropout=dropout)
            for _ in range(num_blocks)
        ])

        self.pool = AttentionalAggregation(
            gate_nn=nn.Sequential(
                nn.Linear(hidden, hidden),
                nn.ReLU(),
                nn.Linear(hidden, 1)
            )
        )

        self.classifier = nn.Sequential(
            nn.Linear(hidden, hidden),
            nn.ReLU(),
            nn.Dropout(0.5),
            nn.Linear(hidden, num_classes)
        )

        self._init_weights()

    def _init_weights(self):
        for m in self.modules():
            if isinstance(m, nn.Linear):
                nn.init.xavier_uniform_(m.weight)
                if m.bias is not None:
                    nn.init.zeros_(m.bias)
            elif isinstance(m, nn.LayerNorm):
                nn.init.ones_(m.weight)
                nn.init.zeros_(m.bias)

    def forward(self, x, edge_index, batch_map):
        x = self.input_proj(x)  # [num_nodes, hidden]

        # Compute hyperedge weights in forward pass so gradients flow
        num_hyperedges = edge_index[1].max().item() + 1
        hyperedge_weight = self.edge_attn(x, edge_index)

        # Apply hypergraph blocks (each with its own FFN)
        for block in self.blocks:
            x = block(x, edge_index, hyperedge_weight)

        out = self.pool(x, batch_map)  # [batch_size, hidden]

        out = self.classifier(out)  # [batch_size, num_classes]
        return out

device = 'cuda' if torch.cuda.is_available() else 'cpu'
print(f"Using device: {device}")

model = HyperVigClassifier(
    in_channels=3*8*8,  # 192 features per patch
    hidden=256,
    num_classes=10,
    num_blocks=3,
    dropout=0.2
).to(device)

optimizer = torch.optim.AdamW(model.parameters(), lr=0.001, weight_decay=0.01, eps=1e-8)

scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=100, eta_min=1e-6)

criterion = nn.CrossEntropyLoss()

def train_epoch(model, loader, optimizer, criterion, device):
    model.train()
    total_loss = 0
    correct = 0
    total = 0

    for images, labels in loader:
        images, labels = images.to(device), labels.to(device)

        node_feats, edge_index, batch_map = image_to_true_hypergraph(images)

        optimizer.zero_grad()
        outputs = model(node_feats, edge_index, batch_map)
        loss = criterion(outputs, labels)
        loss.backward()

        # Gradient clipping for stability
        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)

        optimizer.step()

        total_loss += loss.item() * images.size(0)
        _, predicted = outputs.max(1)
        total += labels.size(0)
        correct += (predicted == labels).sum().item()

    return total_loss / total, correct / total

def validate(model, loader, criterion, device):
    model.eval()
    total_loss = 0
    correct = 0
    total = 0

    with torch.no_grad():
        for images, labels in loader:
            images, labels = images.to(device), labels.to(device)
            node_feats, edge_index, batch_map = image_to_true_hypergraph(images)

            outputs = model(node_feats, edge_index, batch_map)
            loss = criterion(outputs, labels)

            total_loss += loss.item() * images.size(0)
            _, predicted = outputs.max(1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()

    return total_loss / total, correct / total

# Training loop with validation
best_val_acc = 0.0
for epoch in range(100):
    train_loss, train_acc = train_epoch(model, train_loader, optimizer, criterion, device)
    val_loss, val_acc = validate(model, test_loader, criterion, device)

    scheduler.step()

    if np.isnan(train_loss) or np.isnan(val_loss):
        print(f"NaN detected at epoch {epoch+1}! Training stopped.")
        break

    if val_acc > best_val_acc:
        best_val_acc = val_acc
        torch.save(model.state_dict(), 'best_hypergraph_model.pth')

    print(f"Epoch {epoch+1}/100 | "
          f"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f} | "
          f"Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.4f} | "
          f"LR: {scheduler.get_last_lr()[0]:.6f}")

print(f"\nBest Validation Accuracy: {best_val_acc:.4f}")