# -*- coding: utf-8 -*-
"""Dynamic Hypergraph Edge Attention.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1HvCUphCF-PAsJrY7090_HjtdZEPybaKT
"""

import numpy as np
import torch
import torch.nn as nn
import torchvision.transforms as T
import torch.nn.functional as F
from torchvision.datasets import CIFAR100
from torch.utils.data import DataLoader
from torch_geometric.nn import HypergraphConv, AttentionalAggregation
import matplotlib
matplotlib.use('Agg')  # Use non-interactive backend for SSH
import matplotlib.pyplot as plt

# CIFAR-100 normalization values
transform = T.Compose([
    T.ToTensor(),
    T.Normalize(
        mean=[0.5071, 0.4867, 0.4408],
        std=[0.2675, 0.2565, 0.2761]
    )
    ])
train_dataset = CIFAR100(root='./data', train=True, download=True, transform=transform)
test_dataset = CIFAR100(root='./data', train=False, download=True, transform=transform)

print(train_dataset.data.shape)
train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)
test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)

"""# image->hypergraph"""

def image_to_dynamic_hypergraph_edge_attention(images, k_spatial=4, k_feature=4, edge_attn=None):
    batch_node_feats = []
    batch_edge_index = []
    batch_edge_weight = []
    batch_map = []
    node_offset = 0

    for b, img in enumerate(images):
        # img: [C,H,W] -> patches
        C, H, W = img.shape
        patch_size = 8
        patches = img.unfold(1, patch_size, patch_size).unfold(2, patch_size, patch_size)
        patches = patches.permute(1,2,0,3,4).contiguous()       # [num_patches_h, num_patches_w, C, 8,8]
        patches = patches.view(-1, C, patch_size, patch_size)    # [num_nodes, C, 8,8]
        node_feats = patches.view(patches.size(0), -1).to(images.device)  # [num_nodes, 192]
        num_nodes = node_feats.size(0)

        # Spatial eges (static)
        spatial_edges = []
        coords = torch.tensor([[i // (W // patch_size), i % (W // patch_size)] for i in range(num_nodes)], device=images.device)
        dists = torch.cdist(coords.float(), coords.float(), p=2)
        for i in range(num_nodes):
            nn_idx = torch.topk(dists[i], k=k_spatial+1, largest=False).indices[1:]
            for j in nn_idx:
                spatial_edges.append([i, j])

        # Feature edges
        dists_feat = torch.cdist(node_feats.float(), node_feats.float(), p=2)
        feature_edges = []
        for i in range(num_nodes):
            nn_idx = torch.topk(dists_feat[i], k=k_feature+1, largest=False).indices[1:]
            for j in nn_idx:
                feature_edges.append([i, j])

        # Combine edges
        all_edges = torch.tensor(spatial_edges + feature_edges, dtype=torch.long, device=images.device).T

        # Compute edge weights if edge attention module is provided
        if edge_attn is not None:
            edge_weight = edge_attn(node_feats, all_edges)
        else:
            edge_weight = torch.ones(all_edges.size(1), device=images.device)

        batch_node_feats.append(node_feats)
        batch_edge_index.append(all_edges + node_offset)
        batch_edge_weight.append(edge_weight)
        batch_map.append(torch.full((num_nodes,), b, dtype=torch.long, device=images.device))
        node_offset += num_nodes

    x = torch.cat(batch_node_feats, dim=0).float()
    edge_index = torch.cat(batch_edge_index, dim=1)
    edge_weight = torch.cat(batch_edge_weight)
    batch_map = torch.cat(batch_map)
    return x, edge_index, edge_weight, batch_map

class EdgeAttention(nn.Module):
  def __init__(self, in_dim, hidden=64):
    super().__init__()
    self.mlp = nn.Sequential(
        nn.Linear(in_dim*2, hidden),
        nn.ReLU(),
        nn.Linear(hidden, 1)
    )

  def forward(self, x, edge_index):
    row, col = edge_index
    feats = torch.cat([x[row], x[col]], dim=1)
    alpha = self.mlp(feats).squeeze()
    return torch.sigmoid(alpha)

class HyperVigClassifier(nn.Module):
  def __init__(self, in_channels, hidden, num_classes):
    super().__init__()
    self.input_proj = nn.Linear(in_channels, hidden)
    self.conv1 = HypergraphConv(hidden, hidden)
    self.conv2 = HypergraphConv(hidden, hidden)
    self.conv3 = HypergraphConv(hidden, hidden)
    self.norm3 = nn.LayerNorm(hidden)

    self.pool = AttentionalAggregation(gate_nn=nn.Sequential(nn.Linear(hidden, hidden), nn.ReLU(), nn.Linear(hidden, 1)))
    self.classifier = nn.Linear(hidden, num_classes)

  def forward(self, x, edge_index, edge_weight, batch_map):
    x = self.input_proj(x)  # match dimensions (192 -> 256)
    for conv in [self.conv1, self.conv2, self.conv3]:
        x_res = x
        x = F.relu(conv(x, edge_index, edge_weight))
        x = x + x_res  # residual
    out = self.pool(x, batch_map)
    return self.classifier(out)

device = 'cuda' if torch.cuda.is_available() else 'cpu'
model = HyperVigClassifier(in_channels=3*8*8, hidden=256, num_classes=100).to(device)
edge_attn = EdgeAttention(in_dim=3*8*8, hidden=64).to(device)
optimizer = torch.optim.Adam(list(model.parameters()) + list(edge_attn.parameters()), lr=0.001)
criterion = nn.CrossEntropyLoss()

# Lists to store metrics for plotting
train_losses = []
train_accuracies = []
test_losses = []
test_accuracies = []

num_epochs = 100
for epoch in range(num_epochs):
  # Training phase
  model.train()
  edge_attn.train()
  total_loss = 0
  correct = 0
  total = 0
  for images, labels in train_loader:
    images, labels = images.to(device), labels.to(device)
    node_feats, edge_index, edge_weight, batch_map = image_to_dynamic_hypergraph_edge_attention(images, edge_attn=edge_attn)

    optimizer.zero_grad()
    outputs = model(node_feats, edge_index, edge_weight, batch_map)
    loss = criterion(outputs, labels)
    loss.backward()
    optimizer.step()

    total_loss += loss.item() * images.size(0)
    _, predicted = outputs.max(1)
    total += labels.size(0)
    correct += (predicted == labels).sum().item()

  train_loss = total_loss / total
  train_acc = correct / total
  train_losses.append(train_loss)
  train_accuracies.append(train_acc)

  # Testing phase
  model.eval()
  edge_attn.eval()
  test_loss = 0
  test_correct = 0
  test_total = 0
  with torch.no_grad():
    for images, labels in test_loader:
      images, labels = images.to(device), labels.to(device)
      node_feats, edge_index, edge_weight, batch_map = image_to_dynamic_hypergraph_edge_attention(images, edge_attn=edge_attn)
      outputs = model(node_feats, edge_index, edge_weight, batch_map)
      loss = criterion(outputs, labels)
      
      test_loss += loss.item() * images.size(0)
      _, predicted = outputs.max(1)
      test_total += labels.size(0)
      test_correct += (predicted == labels).sum().item()

  test_loss = test_loss / test_total
  test_acc = test_correct / test_total
  test_losses.append(test_loss)
  test_accuracies.append(test_acc)

  print(f"Epoch {epoch+1}/{num_epochs}")
  print(f"  Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}")
  print(f"  Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.4f}")

# Plotting
plt.figure(figsize=(12, 5))

# Plot loss
plt.subplot(1, 2, 1)
plt.plot(range(1, num_epochs + 1), train_losses, label='Train Loss', marker='o')
plt.plot(range(1, num_epochs + 1), test_losses, label='Test Loss', marker='s')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.title('Training and Test Loss')
plt.legend()
plt.grid(True)

# Plot accuracy
plt.subplot(1, 2, 2)
plt.plot(range(1, num_epochs + 1), train_accuracies, label='Train Accuracy', marker='o')
plt.plot(range(1, num_epochs + 1), test_accuracies, label='Test Accuracy', marker='s')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.title('Training and Test Accuracy')
plt.legend()
plt.grid(True)

plt.tight_layout()
plt.savefig('training_curves.png', dpi=150, bbox_inches='tight')
print(f"\nTraining curves saved to 'training_curves.png'")
plt.close()  # Close the figure to free memory