# -*- coding: utf-8 -*-
"""Dynamic Hypergraph Edge Attention.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1HvCUphCF-PAsJrY7090_HjtdZEPybaKT
"""

# pip install torch-geometric  # Commented out - for Colab use only, not needed in regular Python scripts

import numpy as np
import torch
import torch.nn as nn
import torchvision.transforms as T
import torch.nn.functional as F
from torchvision.datasets import CIFAR10
from torch.utils.data import DataLoader
from torch_geometric.nn import HypergraphConv, AttentionalAggregation
import matplotlib
matplotlib.use('Agg')  # Use non-interactive backend for SSH
import matplotlib.pyplot as plt
import neptune
import random

# Training transforms with full AugReg stack (RandAugment, Random Erasing)
transform = T.Compose([
    T.RandAugment(num_ops=1, magnitude=5),
    T.ToTensor(),
    T.Normalize(
        mean=[0.4914, 0.4822, 0.4465],
        std=[0.2470, 0.2435, 0.2616]
    ),
    T.RandomErasing(p=0.25, scale=(0.02, 0.33), ratio=(0.3, 3.3), value=0)  # Random Erasing
])
train_dataset = CIFAR10(root='./data', train=True, download=True, transform=transform)
test_dataset = CIFAR10(root='./data', train=False, download=True, transform=transform)

print(train_dataset.data.shape)
train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)
test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)

"""# image->hypergraph"""

def image_to_true_hypergraph(images, k_spatial=4, k_feature=4):
    batch_node_feats = []
    batch_hyperedge_index = []
    batch_map = []
    node_offset = 0
    edge_id = 0

    for b, img in enumerate(images):
        C, H, W = img.shape
        patch_size = 8

        # Extract patches
        patches = img.unfold(1, patch_size, patch_size).unfold(2, patch_size, patch_size)
        patches = patches.permute(1, 2, 0, 3, 4).contiguous()
        patches = patches.view(-1, C, patch_size, patch_size)
        node_feats = patches.view(patches.size(0), -1).to(images.device)
        num_nodes = node_feats.size(0)

        # Spatial coordinates for spatial hyperedges
        coords = torch.tensor([
            [i // (W // patch_size), i % (W // patch_size)]
            for i in range(num_nodes)
        ], device=images.device, dtype=torch.float)

        dists_spatial = torch.cdist(coords, coords, p=2)

        # Feature distances for feature-based hyperedges
        dists_feat = torch.cdist(node_feats, node_feats, p=2)

        # Create TRUE hyperedges (each hyperedge connects k+1 nodes)
        hyperedge_list = []

        # Spatial hyperedges: for each node, create a hyperedge with its k nearest spatial neighbors
        for i in range(num_nodes):
            nn_idx = torch.topk(dists_spatial[i], k=k_spatial+1, largest=False).indices
            # Create hyperedge: all these nodes belong to one hyperedge
            for node in nn_idx:
                hyperedge_list.append([node.item() + node_offset, edge_id])
            edge_id += 1

        # Feature hyperedges: for each node, create a hyperedge with its k nearest feature neighbors
        for i in range(num_nodes):
            nn_idx = torch.topk(dists_feat[i], k=k_feature+1, largest=False).indices
            for node in nn_idx:
                hyperedge_list.append([node.item() + node_offset, edge_id])
            edge_id += 1

        batch_node_feats.append(node_feats)
        batch_hyperedge_index.extend(hyperedge_list)
        batch_map.append(torch.full((num_nodes,), b, dtype=torch.long, device=images.device))
        node_offset += num_nodes

    x = torch.cat(batch_node_feats, dim=0).float()
    # Convert to PyG hypergraph format: [2, num_edges] where row 0 is nodes, row 1 is hyperedge IDs
    hyperedge_index = torch.tensor(batch_hyperedge_index, dtype=torch.long, device=images.device).T
    batch_map = torch.cat(batch_map)

    return x, hyperedge_index, batch_map

class HyperedgeAttention(nn.Module):
    """Learnable hyperedge attention that's part of the model's forward pass"""
    def __init__(self, in_dim, hidden=64):
        super().__init__()
        self.mlp = nn.Sequential(
            nn.Linear(in_dim, hidden),
            nn.ReLU(),
            nn.Linear(hidden, 1)
        )
        self._init_weights()

    def _init_weights(self):
        for m in self.modules():
            if isinstance(m, nn.Linear):
                nn.init.xavier_uniform_(m.weight)
                if m.bias is not None:
                    nn.init.zeros_(m.bias)

    def forward(self, x, edge_index):
        """
        Compute attention weights for each hyperedge based on aggregated node features.

        x: [num_nodes, feature_dim]
        edge_index: [2, num_connections] - format: [node_ids, hyperedge_ids]
        Returns: edge weights [num_unique_hyperedges]
        """
        node_idx, hyperedge_idx = edge_index
        num_hyperedges = hyperedge_idx.max().item() + 1

        # Aggregate node features for each hyperedge (mean pooling)
        hyperedge_feats = torch.zeros(num_hyperedges, x.size(1), device=x.device, dtype=x.dtype)

        # Use scatter_mean to aggregate features
        hyperedge_feats.index_add_(0, hyperedge_idx, x[node_idx])

        # Count nodes per hyperedge for proper averaging
        counts = torch.zeros(num_hyperedges, device=x.device, dtype=x.dtype)
        counts.index_add_(0, hyperedge_idx, torch.ones_like(node_idx, dtype=x.dtype))
        hyperedge_feats = hyperedge_feats / counts.unsqueeze(1).clamp(min=1)

        # Compute attention scores
        alpha = self.mlp(hyperedge_feats).squeeze(-1)
        alpha = torch.clamp(alpha, min=-5, max=5)

        # prevent zero weights
        return torch.sigmoid(alpha) * 0.9 + 0.1

class HypergraphBlock(nn.Module):
    def __init__(self, hidden_dim, dropout=0.3, ffn_expansion=2):
        super().__init__()
        self.conv = HypergraphConv(hidden_dim, hidden_dim)
        self.norm1 = nn.LayerNorm(hidden_dim, eps=1e-5)
        self.dropout = nn.Dropout(dropout)

        self.ffn = nn.Sequential(
            nn.Linear(hidden_dim, hidden_dim * ffn_expansion),
            nn.ReLU(),
            nn.Dropout(dropout),
            nn.Linear(hidden_dim * ffn_expansion, hidden_dim)
        )
        self.norm2 = nn.LayerNorm(hidden_dim, eps=1e-5)

    def forward(self, x, edge_index, edge_weight):
        # Hypergraph conv w/ residual
        x_res = x
        x = self.conv(x, edge_index, edge_weight)
        x = self.norm1(x)
        x = self.dropout(F.relu(x)) + x_res

        # Feedforward network w/ residual
        x_res = x
        x = self.ffn(x)
        x = self.norm2(x)
        x = self.dropout(x) + x_res

        return x

class HyperVigClassifier(nn.Module):
    def __init__(self, in_channels, hidden, num_classes, num_blocks=3, dropout=0.3):
        super().__init__()
        self.hidden = hidden
        self.input_proj = nn.Linear(in_channels, hidden)
        self.edge_attn = HyperedgeAttention(in_dim=hidden, hidden=64)

        # Multiple hypergraph blocks (each with its own FFN)
        self.blocks = nn.ModuleList([
            HypergraphBlock(hidden, dropout=dropout)
            for _ in range(num_blocks)
        ])

        self.pool = AttentionalAggregation(
            gate_nn=nn.Sequential(
                nn.Linear(hidden, hidden),
                nn.ReLU(),
                nn.Linear(hidden, 1)
            )
        )

        self.classifier = nn.Sequential(
            nn.Linear(hidden, hidden),
            nn.ReLU(),
            nn.Dropout(0.5),
            nn.Linear(hidden, num_classes)
        )

        self._init_weights()

    def _init_weights(self):
        for m in self.modules():
            if isinstance(m, nn.Linear):
                nn.init.xavier_uniform_(m.weight)
                if m.bias is not None:
                    nn.init.zeros_(m.bias)
            elif isinstance(m, nn.LayerNorm):
                nn.init.ones_(m.weight)
                nn.init.zeros_(m.bias)

    def forward(self, x, edge_index, batch_map):
        x = self.input_proj(x)  # [num_nodes, hidden]

        # Compute hyperedge weights in forward pass so gradients flow
        num_hyperedges = edge_index[1].max().item() + 1
        hyperedge_weight = self.edge_attn(x, edge_index)

        # Apply hypergraph blocks (each with its own FFN)
        for block in self.blocks:
            x = block(x, edge_index, hyperedge_weight)

        out = self.pool(x, batch_map)  # [batch_size, hidden]

        out = self.classifier(out)  # [batch_size, num_classes]
        return out

device = 'cuda' if torch.cuda.is_available() else 'cpu'
print(f"Using device: {device}")

model = HyperVigClassifier(
    in_channels=3*8*8,  # 192 features per patch
    hidden=384,  # Increased from 256 to 384
    num_classes=10,
    num_blocks=4,  # Increased from 3 to 4
    dropout=0.2
).to(device)

# Training hyperparameters - change max_epochs here and it will be used throughout
max_epochs = 150  # Increased from 100 to 150 epochs

# Initialize Neptune monitoring
try:
    with open('neptune_api_key.txt', 'r') as f:
        api_token = f.read().strip()
    run = neptune.init_run(
        project="31K-ML-Real/381K-Vision-GNN-Project",
        api_token=api_token,
    )
    # Log hyperparameters
    run["parameters"] = {
        "learning_rate": 0.0005,
        "weight_decay": 0.01,
        "batch_size": 64,
        "hidden_dim": 384,
        "num_blocks": 4,
        "num_classes": 10,
        "patch_size": 8,
        "in_channels": 192,  # 3 * 8 * 8
        "k_spatial": 4,
        "k_feature": 4,
        "max_epochs": max_epochs,
        "scheduler_type": "CosineAnnealingLR",
        "device": 'cuda' if torch.cuda.is_available() else 'cpu',
        "mixup_alpha_start": 0.2,
        "mixup_alpha_end": 0.8,
        "cutmix_alpha_start": 0.2,
        "cutmix_alpha_end": 1.0,
        "augmentation_schedule": "linear_increase",
        "randaugment_ops": 1,
        "randaugment_magnitude": 5,
        "random_erasing_p": 0.25
    }
    neptune_enabled = True
    print("Neptune monitoring initialized successfully")
except Exception as e:
    print(f"Warning: Could not initialize Neptune monitoring: {e}")
    print("Continuing without Neptune monitoring...")
    neptune_enabled = False
    run = None

optimizer = torch.optim.AdamW(model.parameters(), lr=0.0005, weight_decay=0.01, eps=1e-8)  # Lowered from 0.001 to 0.0005

scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=max_epochs, eta_min=1e-6)

criterion = nn.CrossEntropyLoss()

def mixup_data(x, y, alpha=0.8):
    """Mixup augmentation: sample-level blending"""
    lam = np.random.beta(alpha, alpha)
    batch_size = x.size()[0]
    index = torch.randperm(batch_size).to(x.device)
    mixed_x = lam * x + (1 - lam) * x[index, :]
    y_a, y_b = y, y[index]
    return mixed_x, y_a, y_b, lam

def mixup_criterion(criterion, pred, y_a, y_b, lam):
    """Mixup loss computation"""
    return lam * criterion(pred, y_a) + (1 - lam) * criterion(pred, y_b)

def cutmix_data(x, y, alpha=1.0):
    """CutMix augmentation: patch-level blending"""
    lam = np.random.beta(alpha, alpha)
    batch_size = x.size()[0]
    index = torch.randperm(batch_size).to(x.device)
    
    # Get image dimensions (assuming [B, C, H, W])
    _, _, H, W = x.size()
    
    # Generate random bounding box
    cut_rat = np.sqrt(1.0 - lam)
    cut_w = int(W * cut_rat)
    cut_h = int(H * cut_rat)
    
    # Random center
    cx = np.random.randint(W)
    cy = np.random.randint(H)
    
    # Clamp bounding box
    bbx1 = np.clip(cx - cut_w // 2, 0, W)
    bby1 = np.clip(cy - cut_h // 2, 0, H)
    bbx2 = np.clip(cx + cut_w // 2, 0, W)
    bby2 = np.clip(cy + cut_h // 2, 0, H)
    
    # Apply CutMix
    x[:, :, bby1:bby2, bbx1:bbx2] = x[index, :, bby1:bby2, bbx1:bbx2]
    
    # Adjust lambda to match actual pixel ratio
    lam = 1 - ((bbx2 - bbx1) * (bby2 - bby1) / (W * H))
    
    y_a, y_b = y, y[index]
    return x, y_a, y_b, lam

def cutmix_criterion(criterion, pred, y_a, y_b, lam):
    """CutMix loss computation"""
    return lam * criterion(pred, y_a) + (1 - lam) * criterion(pred, y_b)

# Augmentation schedule: start weak, increase over time
def get_augmentation_alpha(epoch, max_epochs, start_alpha=0.2, end_alpha_mixup=0.8, end_alpha_cutmix=1.0):
    """
    Gradually increase augmentation strength over training
    - Start with weak augmentation (alpha=0.2) for easier learning
    - Gradually increase to full strength by end of training
    """
    # Linear schedule: start_alpha -> end_alpha over max_epochs
    progress = epoch / max_epochs
    mixup_alpha = start_alpha + (end_alpha_mixup - start_alpha) * progress
    cutmix_alpha = start_alpha + (end_alpha_cutmix - start_alpha) * progress
    return mixup_alpha, cutmix_alpha

# Lists to store metrics for plotting
train_losses = []
train_accuracies = []
val_losses = []
val_accuracies = []

def train_epoch(model, loader, optimizer, criterion, device, epoch, max_epochs):
    model.train()
    total_loss = 0
    correct = 0
    total = 0

    for images, labels in loader:
        images, labels = images.to(device), labels.to(device)
        
        optimizer.zero_grad()
        
        # Apply MixUp/CutMix with gradually increasing strength
        mixup_alpha, cutmix_alpha = get_augmentation_alpha(epoch, max_epochs, 
                                                           start_alpha=0.2, 
                                                           end_alpha_mixup=0.8, 
                                                           end_alpha_cutmix=1.0)
        
        if random.random() < 0.5:
            # Apply MixUp with scheduled alpha
            images, labels_a, labels_b, lam = mixup_data(images, labels, alpha=mixup_alpha)
            use_cutmix = False
        else:
            # Apply CutMix with scheduled alpha
            images, labels_a, labels_b, lam = cutmix_data(images, labels, alpha=cutmix_alpha)
            use_cutmix = True

        node_feats, edge_index, batch_map = image_to_true_hypergraph(images)

        outputs = model(node_feats, edge_index, batch_map)
        
        # Apply appropriate loss (MixUp or CutMix)
        if use_cutmix:
            loss = cutmix_criterion(criterion, outputs, labels_a, labels_b, lam)
        else:
            loss = mixup_criterion(criterion, outputs, labels_a, labels_b, lam)
        
        # Check for NaN before backward
        if torch.isnan(loss) or torch.isinf(loss):
            print(f"NaN/Inf detected at epoch {epoch+1}, batch, stopping training")
            return None, None
        
        loss.backward()

        # Gradient clipping for stability
        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)

        optimizer.step()

        total_loss += loss.item() * images.size(0)
        _, predicted = outputs.max(1)
        total += labels.size(0)
        correct += (predicted == labels).sum().item()

    return total_loss / total, correct / total

def validate(model, loader, criterion, device):
    model.eval()
    total_loss = 0
    correct = 0
    total = 0

    with torch.no_grad():
        for images, labels in loader:
            images, labels = images.to(device), labels.to(device)
            node_feats, edge_index, batch_map = image_to_true_hypergraph(images)

            outputs = model(node_feats, edge_index, batch_map)
            loss = criterion(outputs, labels)

            total_loss += loss.item() * images.size(0)
            _, predicted = outputs.max(1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()

    return total_loss / total, correct / total

# Training loop with validation
best_val_acc = 0.0
for epoch in range(max_epochs):
    train_loss, train_acc = train_epoch(model, train_loader, optimizer, criterion, device, epoch, max_epochs)
    
    # Check if training returned None (NaN detected)
    if train_loss is None or train_acc is None:
        print(f"Training stopped due to NaN/Inf at epoch {epoch+1}")
        break
    
    val_loss, val_acc = validate(model, test_loader, criterion, device)

    scheduler.step()
    current_lr = scheduler.get_last_lr()[0]

    if np.isnan(train_loss) or np.isnan(val_loss):
        print(f"NaN detected at epoch {epoch+1}! Training stopped.")
        break

    # Store metrics for plotting
    train_losses.append(train_loss)
    train_accuracies.append(train_acc)
    val_losses.append(val_loss)
    val_accuracies.append(val_acc)

    if val_acc > best_val_acc:
        best_val_acc = val_acc
        torch.save(model.state_dict(), 'best_hypergraph_model.pth')

    print(f"Epoch {epoch+1}/{max_epochs} | "
          f"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f} | "
          f"Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.4f} | "
          f"LR: {current_lr:.6f}")
    
    # Log metrics to Neptune
    if neptune_enabled and run is not None:
        run["train/loss"].append(train_loss)
        run["train/accuracy"].append(train_acc)
        run["val/loss"].append(val_loss)
        run["val/accuracy"].append(val_acc)
        run["learning_rate"].append(current_lr)

print(f"\nBest Validation Accuracy: {best_val_acc:.4f}")

# Plotting - only if we have data
if len(train_losses) > 0 and len(val_losses) > 0:
    try:
        plt.figure(figsize=(12, 5))

        # Plot loss
        plt.subplot(1, 2, 1)
        plt.plot(range(1, len(train_losses) + 1), train_losses, label='Train Loss', marker='o')
        plt.plot(range(1, len(val_losses) + 1), val_losses, label='Val Loss', marker='s')
        plt.xlabel('Epoch')
        plt.ylabel('Loss')
        plt.title('Training and Validation Loss')
        plt.legend()
        plt.grid(True)

        # Plot accuracy
        plt.subplot(1, 2, 2)
        plt.plot(range(1, len(train_accuracies) + 1), train_accuracies, label='Train Accuracy', marker='o')
        plt.plot(range(1, len(val_accuracies) + 1), val_accuracies, label='Val Accuracy', marker='s')
        plt.xlabel('Epoch')
        plt.ylabel('Accuracy')
        plt.title('Training and Validation Accuracy')
        plt.legend()
        plt.grid(True)

        plt.tight_layout()
        plt.savefig('training_curves.png', dpi=150, bbox_inches='tight')
        print(f"\nTraining curves saved to 'training_curves.png'")
        
        # Upload plot to Neptune
        if neptune_enabled and run is not None:
            try:
                run["training_curves"].upload('training_curves.png')
                print("Training curves uploaded to Neptune")
            except Exception as e:
                print(f"Warning: Could not upload plot to Neptune: {e}")
        
        plt.close()  # Close the figure to free memory
    except Exception as e:
        print(f"Warning: Could not create plots: {e}")
else:
    print("Warning: No training data collected, skipping plot generation")

# Stop Neptune run
if neptune_enabled and run is not None:
    try:
        run.stop()
        print("Neptune run stopped successfully")
    except Exception as e:
        print(f"Warning: Could not stop Neptune run: {e}")